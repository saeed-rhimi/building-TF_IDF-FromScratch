{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-24T17:54:27.033073Z",
     "start_time": "2023-08-24T17:54:23.394929400Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loading Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4654a247e23bac0d"
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                   text    labels\n0     Ad sales boost Time Warner profit\\n\\nQuarterly...  business\n1     Dollar gains on Greenspan speech\\n\\nThe dollar...  business\n2     Yukos unit buyer faces loan claim\\n\\nThe owner...  business\n3     High fuel prices hit BA's profits\\n\\nBritish A...  business\n4     Pernod takeover talk lifts Domecq\\n\\nShares in...  business\n...                                                 ...       ...\n2220  BT program to beat dialler scams\\n\\nBT is intr...      tech\n2221  Spam e-mails tempt net shoppers\\n\\nComputer us...      tech\n2222  Be careful how you code\\n\\nA new European dire...      tech\n2223  US cyber security chief resigns\\n\\nThe man mak...      tech\n2224  Losing yourself in online gaming\\n\\nOnline rol...      tech\n\n[2225 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n      <td>business</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n      <td>business</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n      <td>business</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n      <td>business</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n      <td>business</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2220</th>\n      <td>BT program to beat dialler scams\\n\\nBT is intr...</td>\n      <td>tech</td>\n    </tr>\n    <tr>\n      <th>2221</th>\n      <td>Spam e-mails tempt net shoppers\\n\\nComputer us...</td>\n      <td>tech</td>\n    </tr>\n    <tr>\n      <th>2222</th>\n      <td>Be careful how you code\\n\\nA new European dire...</td>\n      <td>tech</td>\n    </tr>\n    <tr>\n      <th>2223</th>\n      <td>US cyber security chief resigns\\n\\nThe man mak...</td>\n      <td>tech</td>\n    </tr>\n    <tr>\n      <th>2224</th>\n      <td>Losing yourself in online gaming\\n\\nOnline rol...</td>\n      <td>tech</td>\n    </tr>\n  </tbody>\n</table>\n<p>2225 rows Ã— 2 columns</p>\n</div>"
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('bbc_text_cls.csv')\n",
    "\n",
    "df_sample = df.iloc[:]\n",
    "\n",
    "df_sample"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-24T19:09:09.987391900Z",
     "start_time": "2023-08-24T19:09:09.924359Z"
    }
   },
   "id": "c4ab499a5c93817b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Creating Vocabulary Of All Words"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "121580f17bc10e80"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Saeed\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "0             risen\n1             1.8bn\n2          rejected\n3         greenback\n4            target\n           ...     \n1140    contraction\n1141         report\n1142          shift\n1143           curb\n1144             by\nLength: 1145, dtype: object"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')  # Download the necessary dataset\n",
    "\n",
    "vocab = set()  # Use a set instead of a Series\n",
    "\n",
    "for row in df_sample['text']:\n",
    "    tokens_set = word_tokenize(row.lower())\n",
    "    vocab.update(tokens_set)  # Update the set with unique tokens from each row\n",
    "\n",
    "vocab = pd.Series(list(vocab))# Convert the set back to a Series if necessary\n",
    "\n",
    "vocab"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-24T18:16:21.919949600Z",
     "start_time": "2023-08-24T18:16:21.892480800Z"
    }
   },
   "id": "e1955e03a182f0bd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Old Code For Making Occurrence DataFrame\n",
    "\n",
    "# # Create a new DataFrame with columns reindexed from the word_series\n",
    "# occurrence_df_1 = pd.DataFrame(columns=vocab)\n",
    "# \n",
    "# # Iterate through each document and count occurrences of each word\n",
    "# for column_name in vocab:\n",
    "#     occurrence_df_1[column_name] = df_sample['text'].apply(lambda row: row.count(column_name))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "24977191adb93f0a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Converting Each Word In Documents Into Corresponding Int Number "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cbc4d7ef8a34b3fa"
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "data": {
      "text/plain": "[('ad', 0),\n ('sales', 1),\n ('boost', 2),\n ('time', 3),\n ('warner', 4),\n ('profit', 5),\n ('quarterly', 6),\n ('profits', 7),\n ('at', 8),\n ('us', 9)]"
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the index counter for assigning unique integer IDs\n",
    "idx = 0\n",
    "\n",
    "# Create an empty dictionary to map words to their corresponding integer IDs\n",
    "word2idx = {}\n",
    "\n",
    "# Create an empty list to store tokenized representations of documents\n",
    "tokenized_docs = []\n",
    "\n",
    "# Loop through each document in the 'text' column of the DataFrame\n",
    "for doc in df_sample['text']:\n",
    "    # Tokenize the document by breaking it into lowercase words\n",
    "    words = word_tokenize(doc.lower())\n",
    "    \n",
    "    # Create an empty list to store integer IDs for words in the document\n",
    "    doc_as_int = []\n",
    "    \n",
    "    # Loop through each word in the tokenized words of the document\n",
    "    for word in words:\n",
    "        # Check if the word is not already in the word2idx dictionary\n",
    "        if word not in word2idx:\n",
    "            # Assign the current index value to the word and increment the index\n",
    "            word2idx[word] = idx\n",
    "            idx += 1\n",
    "        \n",
    "        # Append the integer ID of the word to the doc_as_int list\n",
    "        doc_as_int.append(word2idx[word])\n",
    "    \n",
    "    # Append the list of integer IDs for the document to tokenized_docs\n",
    "    tokenized_docs.append(doc_as_int)\n",
    "\n",
    "list(word2idx.items())[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-24T19:09:25.027708700Z",
     "start_time": "2023-08-24T19:09:21.039556800Z"
    }
   },
   "id": "bf004436d27585d1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Making Reverse idx2word Map"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c88fe70d9a3cc137"
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "data": {
      "text/plain": "[(0, 'ad'),\n (1, 'sales'),\n (2, 'boost'),\n (3, 'time'),\n (4, 'warner'),\n (5, 'profit'),\n (6, 'quarterly'),\n (7, 'profits'),\n (8, 'at'),\n (9, 'us')]"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2word = {v:k for k,v in word2idx.items()}\n",
    "\n",
    "list(idx2word.items())[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-24T19:09:29.316614700Z",
     "start_time": "2023-08-24T19:09:29.284039400Z"
    }
   },
   "id": "20501403e7519154"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Generating TF-IDF Matrix from Tokenized Documents "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad4cf779b197f1dc"
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "# Calculate the number of rows in the matrix, which corresponds to the number of documents\n",
    "N = len(df_sample['text'])\n",
    "\n",
    "# Calculate the number of columns in the matrix, which corresponds to the vocabulary size\n",
    "V = len(word2idx)   \n",
    "\n",
    "# Initialize a Term Frequency-Inverse Document Frequency (TF-IDF) matrix with zeros\n",
    "tf = np.zeros((N, V))\n",
    "\n",
    "# Iterate through the tokenized documents and update the TF-IDF matrix\n",
    "for i, doc_as_int in enumerate(tokenized_docs):\n",
    "    # For each word index in the current document, increment the corresponding cell in the TF-IDF matrix\n",
    "    for j in doc_as_int:\n",
    "        tf[i, j] += 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-24T19:09:32.960749200Z",
     "start_time": "2023-08-24T19:09:32.592231900Z"
    }
   },
   "id": "470ff43fbb96781f"
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1., 4., 1., ..., 0., 0., 0.],\n       [0., 0., 1., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 1., 1., 1.]])"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-24T19:09:33.846483300Z",
     "start_time": "2023-08-24T19:09:33.830205500Z"
    }
   },
   "id": "648297fb1ec9c809"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Calculating TF-IDF Weights for Document-Term Matrix"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4d58b01f19d9878e"
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "# Calculate the document frequency for each word in the vocabulary\n",
    "document_freq = np.sum(tf > 0, axis=0)\n",
    "\n",
    "# Calculate the inverse document frequency (IDF) for each word\n",
    "idf = np.log(N / document_freq)\n",
    "\n",
    "# Compute the TF-IDF matrix by element-wise multiplication of TF and IDF\n",
    "tf_idf = tf * idf"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-24T19:09:52.372414600Z",
     "start_time": "2023-08-24T19:09:51.887507400Z"
    }
   },
   "id": "3bdf5e77dd70cc1d"
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[5.22260554, 9.5575688 , 2.86332511, ..., 0.        , 0.        ,\n        0.        ],\n       [0.        , 0.        , 2.86332511, ..., 0.        , 0.        ,\n        0.        ],\n       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n        0.        ],\n       ...,\n       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n        0.        ],\n       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n        0.        ],\n       [0.        , 0.        , 0.        , ..., 7.70751219, 7.70751219,\n        7.70751219]])"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-24T19:09:53.412104500Z",
     "start_time": "2023-08-24T19:09:53.399107600Z"
    }
   },
   "id": "8b4d89e6729005df"
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "outputs": [],
   "source": [
    "# Set the random seed for reproducibility\n",
    "np.random.seed(123)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "443c060226566d7e"
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  sport\n",
      "Text:  Hingis hints at playing comeback\n",
      "\n",
      "Top 5 terms: \n",
      "hingis\n",
      "pattaya\n",
      "thailand\n",
      "95th\n",
      "30th\n"
     ]
    }
   ],
   "source": [
    "# Choose a random document index using the random seed\n",
    "i = np.random.choice(N)\n",
    "\n",
    "# Retrieve the selected row from the DataFrame\n",
    "row = df_sample.iloc[i]\n",
    "\n",
    "# Print the label of the selected document\n",
    "print('Label: ', row['labels'])\n",
    "\n",
    "# Print the first line of text from the selected document\n",
    "print('Text: ', row['text'].split('\\n', 1)[0])\n",
    "\n",
    "# Print the top 5 terms for the selected document\n",
    "print('\\nTop 5 terms: ')\n",
    "\n",
    "# Get the TF-IDF scores for the selected document\n",
    "scores = tf_idf[i]\n",
    "\n",
    "# Get the indices of terms in descending order of their scores\n",
    "indices = (-scores).argsort()\n",
    "\n",
    "# Loop through the top 5 term indices and print their corresponding words\n",
    "for j in indices[:5]:\n",
    "    print(idx2word[j])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-24T19:36:46.666348500Z",
     "start_time": "2023-08-24T19:36:46.660894300Z"
    }
   },
   "id": "a7b54aefa76b48d7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9b5964777bfc4958"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e4fee5b912e704bf"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
